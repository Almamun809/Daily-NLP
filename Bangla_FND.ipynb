{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOtoyrGuVBFyEAExCHuiBF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Almamun809/Daily-NLP/blob/main/Bangla_FND.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/Complete_Bangla_Dataset.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVwhStEAkOew",
        "outputId": "e6e85ae7-ec9d-43df-8740-7f383fbc3b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "'/content/drive/My Drive/JU_IT_FND/Bangla Fake News dataset/Complete_Bangla_Dataset.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk"
      ],
      "metadata": {
        "id": "NR0RPePEeT4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Complete_Bangla_Dataset.csv')"
      ],
      "metadata": {
        "id": "ujlz7F7ukrgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sentence(text):\n",
        "\n",
        "    text = re.sub('[?.`*^()!°¢܌Ͱ̰ߒנ~×Ҡߘ:ҰߑÍ|।;!,&%\\'@#$><A-Za-z0+-9=./''\"\"_০-৯]', '', text)\n",
        "    text = re.sub(r'(\\W)(?=\\1)', '', text)\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\<a href', ' ', text)\n",
        "    text = re.sub(r'&amp;', '', text)\n",
        "    text = re.sub(r'<br />', ' ', text)\n",
        "    text = re.sub(r'\\'', ' ', text)\n",
        "    text = re.sub(r'ߑͰߑ̰ߒנ', '', text)\n",
        "    text = re.sub(r'ߎɰߎɰߎɍ', '', text)\n",
        "\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "df['processed_content'] = df['content'].apply(clean_sentence)"
      ],
      "metadata": {
        "id": "IOfOUnSneDu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sentence(text):\n",
        "\n",
        "    text = re.sub('[?.`*^()!°¢܌Ͱ̰ߒנ~×Ҡߘ:ҰߑÍ|।;!,&%\\'@#$><A-Za-z0+-9=./''\"\"_০-৯]', '', text)\n",
        "    text = re.sub(r'(\\W)(?=\\1)', '', text)\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\<a href', ' ', text)\n",
        "    text = re.sub(r'&amp;', '', text)\n",
        "    text = re.sub(r'<br />', ' ', text)\n",
        "    text = re.sub(r'\\'', ' ', text)\n",
        "    text = re.sub(r'ߑͰߑ̰ߒנ', '', text)\n",
        "    text = re.sub(r'ߎɰߎɰߎɍ', '', text)\n",
        "\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "df['processed_headline'] = df['headline'].apply(clean_sentence)"
      ],
      "metadata": {
        "id": "FqNg7hqCez-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "AcgtH4lsk1OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "XHsb4zmcocF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    See full source and example:\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "xvtYbgy42FSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_content'], df['label'], test_size=0.2, random_state=36)\n",
        "\n",
        "# Convert text data into feature vectors\n",
        "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Passive Aggressive Classifier\n",
        "clf = PassiveAggressiveClassifier(max_iter=60)\n",
        "clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred = clf.predict(X_test_vec)\n",
        "\n",
        "# Calculate accuracy metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label= 0)\n",
        "recall = recall_score(y_test, y_pred, pos_label= 0)\n",
        "f1 = f1_score(y_test, y_pred, pos_label= 0)\n",
        "\n",
        "# Print accuracy metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Test on a single data point\n",
        "single_text = \"প্রাথমিক বৃত্তি পরীক্ষার সংশোধিত ফল প্রকাশ করেছে প্রাথমিক শিক্ষা অধিদপ্তর। আজ বুধবার রাত সাড়ে ১০টার পর এই ফল প্রকাশ করে আগের ফলে ভুলের জন্য দুঃখ প্রকাশ করেছে তারা। গতকাল মঙ্গলবার দুপুরে সচিবালয়ে সংবাদ সম্মেলন করে বৃত্তি পরীক্ষার ফল ঘোষণা করেছিলেন প্রাথমিক ও গণশিক্ষা মন্ত্রণালয়ের প্রতিমন্ত্রী মো. জাকির হোসেন। কিন্তু ‘কারিগরি ত্রুটির’ কারণ দেখিয়ে সন্ধ্যায় এ ফল স্থগিত করা হয়। পরে মন্ত্রণালয় জানিয়েছিল, ‘কারিগরি ত্রুটির’ কারণে স্থগিত প্রাথমিক বৃত্তি পরীক্ষার ফলাফল সংশোধন করে আজ বুধবার বিকেলে প্রকাশ করা হবে। কিন্তু সন্ধ্যায় মন্ত্রণালয় এক সংবাদ বিজ্ঞপ্তিতে জানিয়েছে, স্থগিত ফলাফল আজ রাতের মধ্যে প্রকাশ করা হবে। কিন্তু রাতে কখন প্রকাশ হবে, তা উল্লেখ করা হয়নি। পরে রাত সাড়ে ১০টার পর প্রাথমিক শিক্ষা অধিদপ্তরের মহাপরিচালক শাহ রেজওয়ান হায়াতের সই করা এক বিজ্ঞপ্তিতে বলা হয়, স্থগিত করা ফলাফল পুনর্যাচাই করে প্রকাশ করা হলো।কীভাবে ভুলটি হয়েছে, তার কারণ খুঁজতে গিয়ে জানা গেল, ফল তৈরির সঙ্গে যুক্ত প্রাথমিক শিক্ষা অধিদপ্তরের কারিগরি দলের গাফিলতির কারণেই এমন ভুলের ঘটনা ঘটেছে। আর প্রাথমিক শিক্ষা অধিদপ্তরের এ ‘দায়িত্বহীন কর্মকাণ্ডের’ জন্য এখন হাজারো শিক্ষার্থী ও তাদের অভিভাবকদের মধ্যে ক্ষোভ ও হতাশা তৈরি হয়েছে।\"\n",
        "single_text_vec = vectorizer.transform([single_text])\n",
        "single_text_pred = clf.predict(single_text_vec)\n",
        "print(\"Prediction for single data point:\", single_text_pred)\n",
        "\n",
        "#Confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "plot_confusion_matrix(cm, classes=[0, 1])\n"
      ],
      "metadata": {
        "id": "fk6WeDxknx6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_headline'], df['label'], test_size=0.2, random_state=36)\n",
        "\n",
        "# Convert text data into feature vectors\n",
        "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Passive Aggressive Classifier\n",
        "clf = PassiveAggressiveClassifier(max_iter=60)\n",
        "clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred = clf.predict(X_test_vec)\n",
        "\n",
        "# Calculate accuracy metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label= 0)\n",
        "recall = recall_score(y_test, y_pred, pos_label= 0)\n",
        "f1 = f1_score(y_test, y_pred, pos_label= 0)\n",
        "\n",
        "# Print accuracy metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Test on a single data point\n",
        "single_text = \"প্রাথমিক বৃত্তি পরীক্ষার সংশোধিত ফল প্রকাশ করেছে প্রাথমিক শিক্ষা অধিদপ্তর।\"\n",
        "single_text_vec = vectorizer.transform([single_text])\n",
        "single_text_pred = clf.predict(single_text_vec)\n",
        "print(\"Prediction for single data point:\", single_text_pred)\n",
        "\n",
        "#Confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "plot_confusion_matrix(cm, classes=[0, 1])"
      ],
      "metadata": {
        "id": "zZjMgqLe2N52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_content'], df['label'], test_size=0.2, random_state=3)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict the labels of the test data\n",
        "y_pred = nb_classifier.predict(X_test_vect)\n",
        "\n",
        "# Calculate accuracy metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 score:\", f1)\n",
        "\n",
        "# Test on single data\n",
        "test_data = \"প্রাথমিক বৃত্তি পরীক্ষার সংশোধিত ফল প্রকাশ করেছে প্রাথমিক শিক্ষা অধিদপ্তর। আজ বুধবার রাত সাড়ে ১০টার পর এই ফল প্রকাশ করে আগের ফলে ভুলের জন্য দুঃখ প্রকাশ করেছে তারা। গতকাল মঙ্গলবার দুপুরে সচিবালয়ে সংবাদ সম্মেলন করে বৃত্তি পরীক্ষার ফল ঘোষণা করেছিলেন প্রাথমিক ও গণশিক্ষা মন্ত্রণালয়ের প্রতিমন্ত্রী মো. জাকির হোসেন। কিন্তু ‘কারিগরি ত্রুটির’ কারণ দেখিয়ে সন্ধ্যায় এ ফল স্থগিত করা হয়। পরে মন্ত্রণালয় জানিয়েছিল, ‘কারিগরি ত্রুটির’ কারণে স্থগিত প্রাথমিক বৃত্তি পরীক্ষার ফলাফল সংশোধন করে আজ বুধবার বিকেলে প্রকাশ করা হবে। কিন্তু সন্ধ্যায় মন্ত্রণালয় এক সংবাদ বিজ্ঞপ্তিতে জানিয়েছে, স্থগিত ফলাফল আজ রাতের মধ্যে প্রকাশ করা হবে। কিন্তু রাতে কখন প্রকাশ হবে, তা উল্লেখ করা হয়নি। পরে রাত সাড়ে ১০টার পর প্রাথমিক শিক্ষা অধিদপ্তরের মহাপরিচালক শাহ রেজওয়ান হায়াতের সই করা এক বিজ্ঞপ্তিতে বলা হয়, স্থগিত করা ফলাফল পুনর্যাচাই করে প্রকাশ করা হলো।কীভাবে ভুলটি হয়েছে, তার কারণ খুঁজতে গিয়ে জানা গেল, ফল তৈরির সঙ্গে যুক্ত প্রাথমিক শিক্ষা অধিদপ্তরের কারিগরি দলের গাফিলতির কারণেই এমন ভুলের ঘটনা ঘটেছে। আর প্রাথমিক শিক্ষা অধিদপ্তরের এ ‘দায়িত্বহীন কর্মকাণ্ডের’ জন্য এখন হাজারো শিক্ষার্থী ও তাদের অভিভাবকদের মধ্যে ক্ষোভ ও হতাশা তৈরি হয়েছে।\"\n",
        "test_data_vect = vectorizer.transform([test_data])\n",
        "test_result = nb_classifier.predict(test_data_vect)\n",
        "print(\"Test result:\", test_result)\n",
        "\n",
        "#Confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "plot_confusion_matrix(cm, classes=[0, 1])"
      ],
      "metadata": {
        "id": "nteXE52WukNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_headline'], df['label'], test_size=0.2, random_state=3)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict the labels of the test data\n",
        "y_pred = nb_classifier.predict(X_test_vect)\n",
        "\n",
        "# Calculate accuracy metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 score:\", f1)\n",
        "\n",
        "# Test on single data\n",
        "test_data = \"প্রাথমিক বৃত্তি পরীক্ষার সংশোধিত ফল প্রকাশ করেছে প্রাথমিক শিক্ষা অধিদপ্তর। আজ বুধবার রাত সাড়ে ১০টার পর এই ফল প্রকাশ করে আগের ফলে ভুলের জন্য দুঃখ প্রকাশ করেছে তারা। গতকাল মঙ্গলবার দুপুরে সচিবালয়ে সংবাদ সম্মেলন করে বৃত্তি পরীক্ষার ফল ঘোষণা করেছিলেন প্রাথমিক ও গণশিক্ষা মন্ত্রণালয়ের প্রতিমন্ত্রী মো. জাকির হোসেন। কিন্তু ‘কারিগরি ত্রুটির’ কারণ দেখিয়ে সন্ধ্যায় এ ফল স্থগিত করা হয়। পরে মন্ত্রণালয় জানিয়েছিল, ‘কারিগরি ত্রুটির’ কারণে স্থগিত প্রাথমিক বৃত্তি পরীক্ষার ফলাফল সংশোধন করে আজ বুধবার বিকেলে প্রকাশ করা হবে। কিন্তু সন্ধ্যায় মন্ত্রণালয় এক সংবাদ বিজ্ঞপ্তিতে জানিয়েছে, স্থগিত ফলাফল আজ রাতের মধ্যে প্রকাশ করা হবে। কিন্তু রাতে কখন প্রকাশ হবে, তা উল্লেখ করা হয়নি। পরে রাত সাড়ে ১০টার পর প্রাথমিক শিক্ষা অধিদপ্তরের মহাপরিচালক শাহ রেজওয়ান হায়াতের সই করা এক বিজ্ঞপ্তিতে বলা হয়, স্থগিত করা ফলাফল পুনর্যাচাই করে প্রকাশ করা হলো।কীভাবে ভুলটি হয়েছে, তার কারণ খুঁজতে গিয়ে জানা গেল, ফল তৈরির সঙ্গে যুক্ত প্রাথমিক শিক্ষা অধিদপ্তরের কারিগরি দলের গাফিলতির কারণেই এমন ভুলের ঘটনা ঘটেছে। আর প্রাথমিক শিক্ষা অধিদপ্তরের এ ‘দায়িত্বহীন কর্মকাণ্ডের’ জন্য এখন হাজারো শিক্ষার্থী ও তাদের অভিভাবকদের মধ্যে ক্ষোভ ও হতাশা তৈরি হয়েছে।\"\n",
        "test_data_vect = vectorizer.transform([test_data])\n",
        "test_result = nb_classifier.predict(test_data_vect)\n",
        "print(\"Test result:\", test_result)\n",
        "\n",
        "#Confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "plot_confusion_matrix(cm, classes=[0, 1])"
      ],
      "metadata": {
        "id": "xMRtPjzX3PEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_content'], df['label'], test_size=0.2, random_state=35)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict the labels of the test data\n",
        "y_pred = svm_classifier.predict(X_test_vect)\n",
        "\n",
        "# Calculate accuracy metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 score:\", f1)\n",
        "\n",
        "# Test on single data\n",
        "test_data = \"গুজব দেখাতে বাকি থাকলেও সেটি মিথ্যা না। আমাদের প্রধানমন্ত্রী শেখ হাসিনা নাকি আবার প্রধানমন্ত্রী হবেন? জানালেন তার সহকারী প্রধানমন্ত্রী এসোম সখা চৌধুরী।\"\n",
        "test_data_vect = vectorizer.transform([test_data])\n",
        "test_result = svm_classifier.predict(test_data_vect)\n",
        "print(\"Test result:\", test_result)\n",
        "\n",
        "#Confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "plot_confusion_matrix(cm, classes=[0, 1])"
      ],
      "metadata": {
        "id": "VxfkZDhXzR3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_headline'], df['label'], test_size=0.2, random_state=35)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict the labels of the test data\n",
        "y_pred = svm_classifier.predict(X_test_vect)\n",
        "\n",
        "# Calculate accuracy metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 score:\", f1)\n",
        "\n",
        "# Test on single data\n",
        "test_data = \"গুজব দেখাতে বাকি থাকলেও সেটি মিথ্যা না। আমাদের প্রধানমন্ত্রী শেখ হাসিনা নাকি আবার প্রধানমন্ত্রী হবেন? জানালেন তার সহকারী প্রধানমন্ত্রী এসোম সখা চৌধুরী।\"\n",
        "test_data_vect = vectorizer.transform([test_data])\n",
        "test_result = svm_classifier.predict(test_data_vect)\n",
        "print(\"Test result:\", test_result)\n",
        "\n",
        "#Confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "plot_confusion_matrix(cm, classes=[0, 1])"
      ],
      "metadata": {
        "id": "UhI39BMy3akk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_content'], df['label'], test_size=0.2, random_state=35)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the Logistic Regression classifier\n",
        "lr_classifier = LogisticRegression(max_iter=500)\n",
        "lr_classifier.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict the labels of the test data\n",
        "y_pred = lr_classifier.predict(X_test_vect)\n",
        "\n",
        "# Calculate accuracy metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 score:\", f1)\n",
        "\n",
        "# Test on single data\n",
        "test_data = \"গুজব দেখাতে বাকি থাকলেও সেটি মিথ্যা না। আমাদের প্রধানমন্ত্রী শেখ হাসিনা নাকি আবার প্রধানমন্ত্রী হবেন? জানালেন তার সহকারী প্রধানমন্ত্রী এসোম সখা চৌধুরী।\"\n",
        "test_data_vect = vectorizer.transform([test_data])\n",
        "test_result = lr_classifier.predict(test_data_vect)\n",
        "print(\"Test result:\", test_result)\n",
        "\n",
        "#Confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "plot_confusion_matrix(cm, classes=[0, 1])"
      ],
      "metadata": {
        "id": "VhCfJtLH1N3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_headline'], df['label'], test_size=0.2, random_state=35)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the Logistic Regression classifier\n",
        "lr_classifier = LogisticRegression(max_iter=500)\n",
        "lr_classifier.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict the labels of the test data\n",
        "y_pred = lr_classifier.predict(X_test_vect)\n",
        "\n",
        "# Calculate accuracy metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 score:\", f1)\n",
        "\n",
        "# Test on single data\n",
        "test_data = \"গুজব দেখাতে বাকি থাকলেও সেটি মিথ্যা না। আমাদের প্রধানমন্ত্রী শেখ হাসিনা নাকি আবার প্রধানমন্ত্রী হবেন? জানালেন তার সহকারী প্রধানমন্ত্রী এসোম সখা চৌধুরী।\"\n",
        "test_data_vect = vectorizer.transform([test_data])\n",
        "test_result = lr_classifier.predict(test_data_vect)\n",
        "print(\"Test result:\", test_result)\n",
        "\n",
        "#Confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "plot_confusion_matrix(cm, classes=[0, 1])"
      ],
      "metadata": {
        "id": "y_NAnn7J3kGt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}