{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMK9LkyBGZQVQmoojq/KExI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Almamun809/Daily-NLP/blob/main/hate_speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MstCVbhV7Rf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load data from CSV file\n",
        "data = pd.read_csv('/content/drive/My Drive/path_to_your_csv_file.csv')\n",
        "\n",
        "# Assuming 'text' column contains the text data and 'label' column contains the labels\n",
        "texts = data['text'].tolist()\n",
        "labels = data['label'].tolist()\n",
        "\n",
        "# Split the data into training, evaluation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "\n",
        "# Fit and transform the training data\n",
        "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "# Transform the evaluation data\n",
        "tfidf_eval = tfidf_vectorizer.transform(X_eval)\n",
        "# Transform the testing data\n",
        "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Initialize the Passive Aggressive Classifier\n",
        "pac = PassiveAggressiveClassifier(max_iter=50)\n",
        "\n",
        "# Train the classifier\n",
        "pac.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict on the evaluation set\n",
        "y_pred_eval = pac.predict(tfidf_eval)\n",
        "# Predict on the testing set\n",
        "y_pred_test = pac.predict(tfidf_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_eval, y_pred_eval)\n",
        "precision = precision_score(y_eval, y_pred_eval)\n",
        "recall = recall_score(y_eval, y_pred_eval)\n",
        "f1 = f1_score(y_eval, y_pred_eval)\n",
        "auc = roc_auc_score(y_eval, y_pred_eval)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC:\", auc)\n",
        "\n",
        "# Confusion matrix for evaluation set\n",
        "conf_matrix_eval = confusion_matrix(y_eval, y_pred_eval)\n",
        "print(\"Confusion Matrix (Evaluation Set):\")\n",
        "print(conf_matrix_eval)\n",
        "\n",
        "# Confusion matrix for testing set\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "print(\"Confusion Matrix (Testing Set):\")\n",
        "print(conf_matrix_test)\n",
        "\n",
        "# Calculate testing loss manually\n",
        "testing_loss = pac.score(tfidf_test, y_test)\n",
        "print(\"Testing Loss:\", testing_loss)\n",
        "\n",
        "# Plot training, evaluation, and testing loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(pac.loss_curve_, label='Training Loss', color='blue')\n",
        "plt.plot(np.arange(1, len(pac.loss_curve_) + 1), pac.loss_curve_, marker='o', markersize=5, linestyle='', color='blue')\n",
        "plt.plot(np.arange(1, len(pac.loss_curve_) + 1), pac.loss_curve_, color='blue')\n",
        "plt.axhline(y=pac.validation_scores_[-1], color='red', linestyle='--', label='Evaluation Loss')\n",
        "plt.axhline(y=testing_loss, color='green', linestyle='-.', label='Testing Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training, Evaluation, and Testing Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_eval, pac.decision_function(tfidf_eval))\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    }
  ]
}