{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpDSMlW5h2jlXXKXh/OclQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Almamun809/Daily-NLP/blob/main/HS_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVYxnTSAVNWe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "import sklearn.metrics as metrics\n",
        "import itertools\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the Punkt tokenizer (if not already downloaded)\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Assuming you have your training data in a pandas DataFrame called 'data'\n",
        "X = data['text']  # Features\n",
        "y = data['label']  # Target variable\n",
        "\n",
        "# Preprocessing: Remove URLs, usernames, hashtags, and punctuations\n",
        "def preprocess_text(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
        "    # Remove usernames (e.g., @user)\n",
        "    text = re.sub(r\"@\\w+\", \"\", text, flags=re.MULTILINE)\n",
        "    # Remove hashtags (e.g., #hashtag)\n",
        "    text = re.sub(r\"#\\w+\", \"\", text, flags=re.MULTILINE)\n",
        "    # Remove punctuations (excluding word characters and whitespace)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to the text data\n",
        "X = X.apply(preprocess_text)\n",
        "\n",
        "# Replace NaN values with empty strings\n",
        "X = X.fillna('')\n",
        "\n",
        "# Define the TfidfVectorizer with word_tokenize for word-level unigram features\n",
        "vectorizer = TfidfVectorizer(ngram_range=(2, 4), analyzer='char')\n",
        "\n",
        "# Convert text data into numerical features\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "# Define the Passive Aggressive Classifier\n",
        "classifier = PassiveAggressiveClassifier(max_iter=500, random_state=42, C=1.0)\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store evaluation metric scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "# Iterate over the cross-validation folds\n",
        "for train_index, test_index in kfold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the labels for the test data\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metric scores\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "    recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
        "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "# Calculate average scores across all folds\n",
        "accuracy_avg = np.mean(accuracy_scores)\n",
        "precision_avg = np.mean(precision_scores)\n",
        "recall_avg = np.mean(recall_scores)\n",
        "f1_avg = np.mean(f1_scores)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Accuracy: {accuracy_avg}')\n",
        "print(f'Precision: {precision_avg}')\n",
        "print(f'Recall: {recall_avg}')\n",
        "print(f'F1 Score: {f1_avg}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import sklearn.metrics as metrics\n",
        "import itertools\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have your training data in a pandas DataFrame called 'data'\n",
        "X = data['text']  # Features\n",
        "y = data['label']  # Target variable\n",
        "\n",
        "# Preprocessing: Remove URLs, usernames, hashtags, and punctuations\n",
        "def preprocess_text(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
        "    # Remove usernames (e.g., @user)\n",
        "    text = re.sub(r\"@\\w+\", \"\", text, flags=re.MULTILINE)\n",
        "    # Remove hashtags (e.g., #hashtag)\n",
        "    text = re.sub(r\"#\\w+\", \"\", text, flags=re.MULTILINE)\n",
        "    # Remove punctuations (excluding word characters and whitespace)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to the text data\n",
        "X = X.apply(preprocess_text)\n",
        "\n",
        "# Replace NaN values with empty strings\n",
        "X = X.fillna('')\n",
        "\n",
        "# Define the TfidfVectorizer for word-level unigram features\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
        "\n",
        "# Convert text data into numerical features\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "# Define the Multinomial Naive Bayes Classifier\n",
        "classifier = MultinomialNB()\n",
        "\n",
        "# Perform 3-fold cross-validation\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store evaluation metric scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "# Iterate over the cross-validation folds\n",
        "for train_index, test_index in kfold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the labels for the test data\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metric scores\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
        "    recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
        "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "# Calculate average scores across all folds\n",
        "accuracy_avg = np.mean(accuracy_scores)\n",
        "precision_avg = np.mean(precision_scores)\n",
        "recall_avg = np.mean(recall_scores)\n",
        "f1_avg = np.mean(f1_scores)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Accuracy: {accuracy_avg}')\n",
        "print(f'Precision: {precision_avg}')\n",
        "print(f'Recall: {recall_avg}')\n",
        "print(f'F1 Score: {f1_avg}')\n",
        "\n",
        "#Confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "plot_confusion_matrix(cm, classes=[0, 1])"
      ],
      "metadata": {
        "id": "b4u2MBE4pu_2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}